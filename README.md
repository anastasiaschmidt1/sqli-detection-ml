# SQL Injection Detection

--------

## ğŸš¨ **Wichtige Anmerkung** ğŸš¨

**Dieses Projekt wurde im Rahmen des Moduls "Wissenschaftliches Projekt" an der Berliner Hochschule fÃ¼r Technik (BHT) im Wintersemester 2024/2025 erstellt.**

Es werden Vorlagen aus dem Modul **"KÃ¼nstliche Intelligenz"** verwendet und zudem wurde das Projekt mit Hilfe von **ChatGPT**ğŸ˜± entwickelt und ist komplett in **Deutsch**ğŸ˜±ğŸ˜±.

**âš ï¸ Es wird darauf hingewiesen, dass dieses Projekt keine Garantie auf die QualitÃ¤t oder die fehlerfreie Funktion des Codes gibt. Jegliche Nutzung des Projekts erfolgt auf **eigene Verantwortung****

--------

## ProjektÃ¼bersicht
Dieses Projekt zur Erkennung von SQL-Injection-Angriffen nutzt maschinelles Lernen (SVM-Modell), um SQL-Injection-Angriffe anhand von Benutzereingaben zu identifizieren.

Die **Daten** stammen von [Kaggle: SQL Injection Dataset](https://www.kaggle.com/datasets/syedsaqlainhussain/sql-injection-dataset), das SQL-Injection-Strings sowie normale Benutzereingaben enthÃ¤lt. Nach der Bereinigung werden die Daten in **Trainingsdaten** und **Testdaten** aufgeteilt, um das Modell zu trainieren und zu evaluieren.

--------

## Projektstruktur
Das Projekt ist wie folgt strukturiert:

```
sqli-detection-ml/
â”‚
â”œâ”€â”€ data/                         
â”‚   â”œâ”€â”€ raw/                       # Rohdaten
â”‚   â”‚   â””â”€â”€ SQLiV3.csv             
â”‚   â”œâ”€â”€ processed/                 # Bereinigte Daten (generierte Datei)
â”‚   â”‚   â””â”€â”€ SQLiV3-processed.csv  
â”‚   â”œâ”€â”€ data-train.csv             # Trainingsdaten (generierte Datei)
â”‚   â””â”€â”€ data-test.csv              # Testdaten (generierte Datei)
â”‚   â””â”€â”€ README-data.md             
â”‚
â”œâ”€â”€ helper/                       
â”‚   â”œâ”€â”€ format_data.py             # Skript zur Bereinigung der Daten
â”‚   â””â”€â”€ split_data.py              # Skript zur Aufteilung der Daten
â”‚
â”œâ”€â”€ models/                        
â”‚   â”œâ”€â”€ svm_model.pkl              # Trainiertes SVM-Modell (generierte Datei)
â”‚   â””â”€â”€ vectorizer.pkl             # Vektorisierer (generierte Datei)
â”‚
â”œâ”€â”€ training/                      
â”‚   â”œâ”€â”€ svm_model.py               # Logik fÃ¼r Modelltraining und Vorhersagen
â”‚   â”œâ”€â”€ test_svm_model.py          # Tests fÃ¼r das Modell
â”‚
â”œâ”€â”€ .gitignore   
â”œâ”€â”€ main.py                        # Hauptskript fÃ¼r Training und Vorhersagen
â”œâ”€â”€ README.md                      
â””â”€â”€ requirements.txt               # AbhÃ¤ngigkeiten
```
--------

## Installation und Nutzung

### Getestete Umgebung
Das Projekt wurde in **Anaconda** mit **Python 3.12.7** getestet. _(Anaconda ist eine Python-Distribution, die speziell fÃ¼r Data-Science- und maschinelles Lernen optimiert wurde. Sie bietet eine einfache Verwaltung von Python-Versionen und AbhÃ¤ngigkeiten.)_

Die folgenden Versionen der Bibliotheken wurden verwendet:

* **pandas: 2.2.2**
* **scikit-learn: 1.5.1**
* **joblib: 1.4.2**
* **numpy: 1.26.4**

### AbhÃ¤ngigkeiten
Das Projekt benÃ¶tigt folgende Python-Pakete, die fÃ¼r das Datenmanagement, Modelltraining und Vorhersagen zustÃ¤ndig sind:

**pandas:** Wird zur Verarbeitung und Manipulation von Daten verwendet. Es stellt leistungsfÃ¤hige Datenstrukturen wie DataFrames zur VerfÃ¼gung, die fÃ¼r das Projekt zur Speicherung und Analyse der SQL-Abfragen genutzt werden.

**scikit-learn:** Wird fÃ¼r das maschinelle Lernen verwendet. Diese Bibliothek enthÃ¤lt zahlreiche Algorithmen, einschlieÃŸlich SVM (Support Vector Machine), die im Projekt zur Erkennung von SQL-Injection-Angriffen eingesetzt wird.

**joblib:** Wird zur Serialisierung des Modells und des Vektorisierers verwendet. Dies ermÃ¶glicht es, das trainierte Modell und den Vektorisierer zu speichern und spÃ¤ter wieder zu laden.

**numpy:** Wird fÃ¼r numerische Berechnungen verwendet und ist eine grundlegende Bibliothek fÃ¼r die Arbeit mit Arrays und Matrizen, die in vielen Algorithmen von scikit-learn erforderlich sind.


Installiere alle AbhÃ¤ngigkeiten mit:
```bash
pip install -r requirements.txt
```

### Nutzung

1. **Daten bereinigen**:
```bash
python helper/format_data.py
```
2. **Daten aufteilen**:
 ```bash
python helper/split_data.py
```
3. **Modell trainieren**:
```bash
python main.py train
```
4. **Modell testen**:
```bash
python main.py test
```
5. **Vorhersage durchfÃ¼hren**:
```
python main.py predict --query "DEINE_BEISPIEL_EINGABE"
```
Beispiel: Wenn du eine SQL-Abfrage vorhersagen mÃ¶chtest, kannst du das Modell wie folgt verwenden:
```bash
python main.py predict --query "SELECT * FROM users WHERE id='1' OR 1=1 --"
```
Dies gibt zurÃ¼ck, ob es sich um eine SQL-Injection handelt (`SQLi`) oder nicht (`Normal`).

--------

## Modellbeschreibung

Das Modell verwendet einen **Support Vector Machine (SVM)**-Algorithmus, um zwischen **SQL-Injection-Angriffen** und **normalen Benutzereingaben** zu unterscheiden. Der SVM-Algorithmus wurde mit einem Datensatz von SQL-Injection-Strings und normalen SQL-Abfragen trainiert.

Ein wesentlicher Bestandteil des Modells ist die **Vektorisierung der SQL-Abfragen**. Es wird `CountVectorizer` aus der Bibliothek **`scikit-learn`** verwendet, um die Textdaten in **numerische Vektoren** zu transformieren. Dabei wird **n-Gramme**, also Kombinationen von aufeinanderfolgenden Zeichen berÃ¼cksichtigt. Dies hilft dem Modell, **Zeichenfolgenmuster** zu erkennen, die typisch fÃ¼r SQL-Injections sind.

Der **Vektorisierer** (gespeichert als `vectorizer.pkl`) extrahiert sowohl **einzelne Zeichen (1-Gramme)** als auch **zwei aufeinanderfolgende Zeichen (2-Gramme)** aus den SQL-Abfragen. Dies ermÃ¶glicht es dem Modell, komplexe Muster zu erkennen, die in SQL-Injection-Angriffen hÃ¤ufig auftreten, wie z.B. die Kombination `--` oder `1=1`.

Das trainierte Modell wird als **`svm_model.pkl`** gespeichert und kann fÃ¼r Vorhersagen auf neuen SQL-Abfragen verwendet werden.
